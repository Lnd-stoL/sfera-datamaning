
# sfera-datamining

./users-info-extractions  - 1-я домашка
./features-analysis       - 2-я домашка
./clasterizing            - 3-я домашка
./twitter-text-analysis   - 4-я домашка

./data/lists              - некоторые исходные данные
./data/twitts-text        - данные, с которыми работает 4-я домашка

======================================


# 4-я домашка
в ./twitter-text-analysis 

    !!! для облака тэгов нужна библиотека 
        https://github.com/amueller/word_cloud 
        
    !!! смтореть на облако лучше на картинке - ./data/twitts-text/tag_cloud.png (она большого разрешения)
    
    !!! скрипты работают достаточно долго (обработчик текста и генератор облака порядка 5 ~ 10 минут)

        
=== скрипты

collect_text_data.py  -  скрипт собирает тексты постов из твиттера, фильтруя репосты, ответы, ссылки и т.д.
                         собранные данные сохраняются в базе данных для последующего использования
                         
text_data_processor   -  обрабатывает сохранённые ранее в базу тексты твитов
                         сохраняет матрицу (пользователи Х слова)
                         
text_tagcloud.py      -  рисует, сохраняет и показывает облако тэгов


=== файлы данных в ./data/twitts-text

tag_cloud.png                   -  облако тэгов (картинка)

bad_requests.txt                -  сюда сохраняются айди пользователей, для которых не удалосб получить твиты при сборке
raw_tweets                      -  база данных с твитами, генерируемая сборщиком
tag_cloud_mask.png
text_tokens.npz

tokens_dictionary.txt           -  получившийся после обработки текста словарь
words_frequency_statistics.txt  -  список, отсортированных по частоте использования (с указанием частоты использования)
